# üìä AI-Powered Dashboard Generator

An intelligent dashboard system that converts natural language questions into interactive visualizations without requiring any SQL knowledge. Simply upload your data, ask questions in plain English, and get instant insights powered by AI.

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.32+-red.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

## üåü Features

### üöÄ Core Capabilities
- **Natural Language Queries**: Ask questions in plain English - no SQL knowledge required
- **Multi-Format Support**: Upload CSV, Excel (.xlsx), or SQLite databases
- **Automatic Conversion**: Converts uploaded files to SQLite automatically
- **AI-Powered SQL Generation**: Uses LLM (Gemini/Claude/OpenAI) to generate queries
- **Smart Visualizations**: Automatically creates appropriate charts (bar, line, pie, scatter, area)
- **Interactive Dashboards**: Fully interactive Plotly charts with zoom, pan, and hover details
- **Query History**: Saves all queries and visualizations in your session
- **Data Export**: Download results as CSV or SQLite database

### üîí Security Features
- **Read-Only Queries**: Only SELECT queries allowed - no data modification
- **SQL Injection Protection**: Multi-layer validation and sanitization
- **Query Validation**: AST-based parsing to prevent malicious queries
- **Safe Execution**: Automatic timeouts and row limits

### ü§ñ AI Provider Support
- **Google Gemini** (Free tier available)
- **Anthropic Claude** (Most accurate)
- **OpenAI GPT-4** (Balanced performance)

---

## üì∏ Screenshots

### Main Dashboard
![Dashboard Interface](screenshots/dashboard.png)

### File Upload
![File Upload](screenshots/upload.png)

### Visualization Example
![Chart Example](screenshots/visualization.png)

---

## üöÄ Quick Start

### Prerequisites

- Python 3.10 or higher
- pip (Python package manager)
- API key from one of: [Gemini](https://makersuite.google.com/app/apikey) (Free), [Claude](https://console.anthropic.com), or [OpenAI](https://platform.openai.com)

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/ai-dashboard-generator.git
cd ai-dashboard-generator
```

2. **Create virtual environment**
```bash
python -m venv venv

# On Windows
venv\Scripts\activate

# On Mac/Linux
source venv/bin/activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Create `.env` file**
```bash
# Copy the example file
cp .env.example .env

# Edit .env and add your API key
# GOOGLE_API_KEY=your_gemini_api_key_here
```

5. **Run the application**
```bash
streamlit run app.py
```

The app will open in your browser at `http://localhost:8501`

---

## üìñ Usage Guide

### Step 1: Configure AI Provider

1. Open the sidebar
2. Select your LLM provider (Gemini recommended for free tier)
3. Enter your API key
4. Wait for "‚úÖ LLM Configured" status

### Step 2: Upload Your Data

**Option A: Upload Files**
1. Click "Upload File" tab in sidebar
2. Select file type (CSV, Excel, or SQLite)
3. Choose your file(s)
4. Click "Import"

**Option B: Connect to Database**
1. Click "Connect" tab in sidebar
2. Enter connection details
3. Click "Connect"

### Step 3: Ask Questions

Type natural language questions like:
- "Show total sales by region"
- "What are the top 10 customers by revenue?"
- "Display monthly trends"
- "Which products sell the most?"

### Step 4: Analyze Results

- View auto-generated visualizations
- Examine the SQL query that was generated
- Download data as CSV
- Review query history

---

## üí° Example Questions

### Basic Queries
```
- Show all records from [table_name]
- How many rows are in this dataset?
- What columns are available?
- Display the first 10 rows
```

### Analytics
```
- Show top 10 [items] by [metric]
- What's the average [value] by [category]?
- Display [metric] trends over time
- Compare [metric] across [groups]
```

### Complex Analysis
```
- Which [items] have [metric] above average?
- Show correlation between [field1] and [field2]
- Display [metric] distribution by [category] and [subcategory]
- What percentage of [items] meet [condition]?
```

---

## üìÅ Project Structure
```
ai-dashboard-generator/
‚îÇ
‚îú‚îÄ‚îÄ app.py                         # Main Streamlit application
‚îú‚îÄ‚îÄ llm_query_generator.py         # AI-powered SQL generation
‚îú‚îÄ‚îÄ sql_validator.py               # Security validation
‚îú‚îÄ‚îÄ schema_inspector.py            # Database schema extraction
‚îú‚îÄ‚îÄ visualization_generator.py     # Chart generation
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt               # Python dependencies
‚îú‚îÄ‚îÄ .env.example                   # Environment variables template
‚îú‚îÄ‚îÄ .gitignore                     # Git ignore rules
‚îÇ
‚îú‚îÄ‚îÄ README.md                      # This file
‚îú‚îÄ‚îÄ LICENSE                        # MIT License
‚îÇ
‚îî‚îÄ‚îÄ screenshots/                   # Documentation images
    ‚îú‚îÄ‚îÄ dashboard.png
    ‚îú‚îÄ‚îÄ upload.png
    ‚îî‚îÄ‚îÄ visualization.png
```

---

## üîß Configuration

### Environment Variables

Create a `.env` file in the project root:
```env
# AI Provider (choose one)
GOOGLE_API_KEY=your_gemini_api_key_here
# ANTHROPIC_API_KEY=your_claude_api_key
# OPENAI_API_KEY=your_openai_api_key

# Optional: Database connection (if connecting to existing DB)
DATABASE_URL=sqlite:///your_database.sqlite

# Optional: Advanced settings
MAX_QUERY_ROWS=10000
QUERY_TIMEOUT=30
```

### Getting API Keys

**Google Gemini (Free Tier):**
1. Go to [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Click "Get API Key"
3. Create or select a project
4. Copy the API key
5. Free tier: 60 requests/minute

**Anthropic Claude:**
1. Visit [Anthropic Console](https://console.anthropic.com)
2. Sign up (requires credit card)
3. Go to API Keys section
4. Create new key
5. Pay-as-you-go pricing

**OpenAI GPT-4:**
1. Go to [OpenAI Platform](https://platform.openai.com)
2. Sign up (requires credit card)
3. Navigate to API Keys
4. Create new secret key
5. Pay-as-you-go pricing

---

## üé® Supported File Formats

### CSV Files
- Single or multiple CSV files
- Each file becomes a separate table
- Automatic column name cleaning
- Handles various encodings (UTF-8, Latin-1, etc.)

**Example:**
```csv
product,category,sales,date
Laptop,Electronics,1200,2024-01-15
Phone,Electronics,800,2024-01-16
```

### Excel Files (.xlsx, .xls)
- All sheets imported as separate tables
- Preserves data types
- Handles complex spreadsheets

**Supported:**
- Multiple sheets
- Formatted cells
- Formulas (values only)

### SQLite Databases
- Direct upload of .db or .sqlite files
- No conversion needed
- Preserves all relationships and indexes

---

## üìä Visualization Types

The system automatically selects the best chart type:

| Chart Type | Best For | Example Question |
|------------|----------|------------------|
| **Bar Chart** | Comparisons, rankings | "Top 10 products by sales" |
| **Line Chart** | Trends over time | "Monthly revenue over the year" |
| **Pie Chart** | Parts of whole (‚â§10 categories) | "Sales distribution by region" |
| **Scatter Plot** | Correlation between variables | "Price vs. sales volume" |
| **Area Chart** | Cumulative values | "Running total of orders" |
| **Table** | Detailed data, many columns | "Show all customer details" |

---

## üîí Security

### Built-in Protection

1. **Query Validation**
   - Only SELECT statements allowed
   - Blocks INSERT, UPDATE, DELETE, DROP
   - Prevents SQL injection attacks

2. **Safe Execution**
   - Read-only database access
   - Automatic query timeouts (30 seconds)
   - Row limit enforcement (10,000 max)

3. **Data Privacy**
   - All processing happens locally
   - No data sent to third parties (except LLM API for query generation)
   - API keys stored in environment variables

### Best Practices
```python
# ‚úÖ Good: Use read-only database credentials
DATABASE_URL=postgresql://readonly_user:password@localhost/db

# ‚ùå Bad: Never use admin credentials
DATABASE_URL=postgresql://admin:password@localhost/db
```

---

## üõ†Ô∏è Troubleshooting

### Common Issues

**Issue: "No module named 'streamlit'"**
```bash
# Solution: Install dependencies
pip install -r requirements.txt
```

**Issue: "Database connection failed"**
```bash
# Solution: Check database is running
# For SQLite: Verify file exists
ls your_database.sqlite

# For PostgreSQL:
pg_isready

# For MySQL:
mysqladmin ping
```

**Issue: "API key invalid"**
```bash
# Solution: Verify API key
# 1. Check .env file exists
# 2. Ensure no extra spaces
# 3. Try regenerating key
```

**Issue: "Failed to parse JSON response"**
```bash
# Solution: LLM returned malformed JSON
# The system has multiple fallback parsers
# Check the "Raw Response" in error details
# If persistent, try a different AI provider
```

**Issue: CSV import error with special characters**
```bash
# Solution: The system tries multiple encodings
# If fails, try opening CSV in Excel and re-saving
# Or manually convert to UTF-8 encoding
```

---

## üöÄ Advanced Usage

### Custom Database Connection
```python
# PostgreSQL
DATABASE_URL=postgresql://user:password@localhost:5432/database

# MySQL
DATABASE_URL=mysql+pymysql://user:password@localhost:3306/database

# SQLite (relative path)
DATABASE_URL=sqlite:///data/database.sqlite

# SQLite (absolute path)
DATABASE_URL=sqlite:////full/path/to/database.sqlite
```

### Programmatic Usage
```python
from llm_query_generator import TextToSQLGenerator
from schema_inspector import SchemaInspector

# Initialize
generator = TextToSQLGenerator(provider="gemini")
inspector = SchemaInspector("sqlite:///mydb.sqlite")

# Get schema
schema = inspector.get_schema_for_llm()

# Generate SQL
result = generator.generate_sql(
    question="Show top 10 customers",
    schema_description=schema
)

print(result['sql'])
```

---

## ü§ù Contributing

We welcome contributions! Here's how:

1. **Fork the repository**
2. **Create a feature branch**
```bash
   git checkout -b feature/amazing-feature
```
3. **Make your changes**
4. **Run tests**
```bash
   python -m pytest tests/
```
5. **Commit your changes**
```bash
   git commit -m "Add amazing feature"
```
6. **Push to your fork**
```bash
   git push origin feature/amazing-feature
```
7. **Open a Pull Request**

### Development Setup
```bash
# Install development dependencies
pip install -r requirements-dev.txt

# Run tests
pytest

# Run linter
flake8 .

# Format code
black .
```

---

## üìù License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
```
MIT License

Copyright (c) 2024 Ahmad Hussain

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

---

## üôè Acknowledgments

- **Streamlit** - For the amazing web framework
- **Plotly** - For interactive visualizations
- **Anthropic/OpenAI/Google** - For powerful LLM APIs
- **SQLAlchemy** - For database abstraction
- **Community contributors** - For bug reports and improvements

---

## üìû Support

- **Documentation**: [Wiki](https://github.com/yourusername/ai-dashboard-generator/wiki)
- **Issues**: [GitHub Issues](https://github.com/yourusername/ai-dashboard-generator/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/ai-dashboard-generator/discussions)
- **Email**: your.email@example.com

---

## üó∫Ô∏è Roadmap

### Version 1.x (Current)
- [x] Multi-format file upload (CSV, Excel, SQLite)
- [x] Natural language query interface
- [x] Multiple LLM provider support
- [x] Interactive visualizations
- [x] Query history

### Version 2.0 (Planned)
- [ ] Real-time collaboration features
- [ ] Scheduled report generation
- [ ] Dashboard templates
- [ ] Advanced analytics (correlation, regression)
- [ ] Custom visualization builder
- [ ] API endpoint for programmatic access
- [ ] Multi-user authentication
- [ ] Database write operations (with approval workflow)

### Version 3.0 (Future)
- [ ] AI-powered insights and recommendations
- [ ] Natural language data updates
- [ ] Predictive analytics
- [ ] Integration with cloud data sources (BigQuery, Snowflake)
- [ ] Mobile app

---

## üìä Performance

### Benchmarks

| Operation | Time | Notes |
|-----------|------|-------|
| CSV Import (1MB) | ~2s | Automatic conversion to SQLite |
| Excel Import (5 sheets) | ~5s | All sheets processed |
| Schema Loading | <1s | Cached after first load |
| LLM Query Generation | 2-5s | Depends on provider |
| Query Execution | <1s | For typical queries |
| Visualization Rendering | <500ms | Client-side rendering |

### Scalability

- **Max CSV size**: 100MB (recommended)
- **Max rows per query**: 10,000 (configurable)
- **Concurrent users**: Limited by Streamlit (single-threaded)
- **Database size**: No limit (SQLite supports up to 281TB)

---

## üß™ Testing

### Run Tests
```bash
# Run all tests
pytest

# Run specific test file
pytest tests/test_sql_validator.py

# Run with coverage
pytest --cov=. --cov-report=html

# View coverage report
open htmlcov/index.html
```

### Test Coverage

Current test coverage: **85%**

- SQL Validator: 95%
- Schema Inspector: 80%
- LLM Generator: 75%
- Visualization: 90%

---

## üìö Additional Resources

### Tutorials
- [Getting Started Guide](docs/getting-started.md)
- [Advanced Queries](docs/advanced-queries.md)
- [Custom Visualizations](docs/custom-viz.md)
- [API Integration](docs/api-integration.md)

### Example Datasets
- [Sample Sales Data](examples/sales_data.csv)
- [Healthcare Data](examples/healthcare.csv)
- [E-commerce Data](examples/ecommerce.sqlite)

### Video Tutorials
- [5-Minute Quickstart](https://youtube.com/watch?v=example)
- [Advanced Features](https://youtube.com/watch?v=example)
- [Data Security Best Practices](https://youtube.com/watch?v=example)

---

## ‚≠ê Star History

[![Star History Chart](https://api.star-history.com/svg?repos=Ahmadhussain99/ai-dashboard-generator&type=Date)](https://star-history.com/#Ahmadhussain99/ai-dashboard-generator&Date)

---

## üíñ Sponsors

This project is made possible by:

- [Individual Sponsors](https://github.com/sponsors/Ahmadhussain99)

[Become a sponsor](https://github.com/sponsors/Ahmadhussain99)

---

<div align="center">

**Made with ‚ù§Ô∏è by [Ahmad](https://github.com/Ahmadhussain99)**

[‚¨Ü Back to Top](#-ai-powered-dashboard-generator)

</div>
